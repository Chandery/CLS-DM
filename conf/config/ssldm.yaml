name: 'ssldm'
#****** Data settings ******
image_size: 128 # resize input images to this size
# pad_channel: 16
resize_size: [128,128,128]
# img_resize_size: [256,256] 
img_resize_size: [128,128] # ? X光的resize size改回128，这样才合理
data_path: "/path"   #feijiejie
dataroot: "/path"   #feijiejie
CT_MEAN_STD: [0., 1.]
XRAY1_MEAN_STD: [0., 1.]
XRAY2_MEAN_STD: [0., 1.0]
XRAY1_MIN_MAX: [0, 255]
XRAY2_MIN_MAX: [0, 255]
CT_MIN_MAX: [0, 2500]
DATA_MIN_MAX: [0, 4095]
fine_size: 128
# fine_size_cond: 256
fine_size_cond: 128 # ? X光的resize size改回128，这样才合理
ct_channel: 128
xray_channel: 1
cond_flag: "unclip" # ? "clip" or "unclip" clip means use pretrained clipae/ unclip means use unet
 
train_datasetfile: "./data/train.txt"
val_datasetfile: "./data/test.txt"
  
# cond_path: "/disk/ssy/data/drr/result/split2/feijiejieDR"

# cond_path: "/disk/ssy/data/drr/result/split/penguDR/" 
# data_path: "/disk/ssy/data/drr/pengu/all/"

output_dir : "./logs/${config.name}"  # the traning logs saved

latent_diffusion:
  # ckpt: True
  # ckpt_path: "/disk/cc/Xray-Diffsuion/logs/ldm/pl_train_ldm-2024-11-08/21-50-19/pl_train_autoencoder-epoch870-val_rec_loss0.00.ckpt"
  base_learning_rate: 5.e-5
  linear_start: 0.0015
  linear_end: 0.0155
  num_timesteps_cond: 1
  high_low_mode: False
  cond_nums: [1,2]   #[1,2,3]
  batch_size: ${config.batch_size}
  dpm_type: "dpm-solver"


  log_every_t: 200
  timesteps: 1000 # ! default 1000
  loss_type: l1

  first_stage_key: "image"
  cond_stage_key: "image"

  image_size: 16
  channels: 4

  cond_stage_trainable: False
  concat_mode: True
  scale_by_std: True
  monitor: 'val/ssim'
  first_stage_config:
    fine_size_cond: 128 # ? X光的resize size改回128，这样才合理
    cond_nums: [1, 2]   #[1,2,3]
    cond_size: 256 # resize condition images to this size

    cond1_order: [0,1,2,3,4]
    cond2_order: [0,1,4,3,2]
    cond3_order: [0,1,4,2,3]

    cond_loss_ratio: 1.e4
    nll_loss_ratio: 1.0
    kl_loss_ratio: 1.e-2

    trainer:
      precision: "32"

    # cond_type: 'add' # 'add' or 'cat'
    cond_type: 'add' # 'add' or 'cat'

    cond_model_config:
      patch_size: 16
      embed_dim: 256
      num_heads: 8
      depth: 16
    
    ae_ckpt: "path"
    clipae_ckpt: "path"

    model:
      base_learning_rate: 0.0001
      sync_dist: True
      # params:
      monitor: "val/loss_ema" 
      embed_dim: 4
      ddconfig:
        double_z: True
        z_channels: 4
        resolution: 128
        in_channels: 1
        out_ch: 1
        ch: 32
        ch_mult: [1,2,4,8]  # num_down = len(ch_mult)-1   #1 2 2 2 4
        num_res_blocks: 2
        attn_resolutions: []
        dropout: 0.0
      lossconfig:
        disc_start: 10000
        kl_weight: 1.0e-4
        disc_weight: 0.5
        highlow_weight: 0
        high_limit: 0.04
        low_limit: 0.04
        disc_in_channels: 1
        perceptual_weight: 0

  unet_config:
    dims: 3
    image_size: 16
    #  in_channels: 28 # ? 3 conds + z
    in_channels: 20 # ? cond1 + cond2 = 16, z = 4
    # in_channels: 132 # ? cond1 + cond2 = 128, z = 4
    out_channels: 4
    model_channels: 32
    attention_resolutions: [1,2,4,8]
    # attention_resolutions: []
    num_res_blocks: 2
    channel_mult: [1,2,3,4]
    num_heads: 8
    use_spatial_transformer: False
    use_scale_shift_norm: True
    resblock_updown: True
    use_fp16: True

    # context_dim: 4
    transformer_depth: 1
    use_checkpoint: true # save_memory
    legacy: False

  scheduler_config:
    # warm_up_steps: [10000]
    # cycle_lengths: [18300000000]
    # f_start: [1.e-6]
    # f_max: [1.]
    # f_min: [1.e-6]
    # verbosity_interval: 100
    interval: "epoch"
    step_size: 200
    gamma: 0.8


trainer:
  benchmark: True
  accumulate_grad_batches: 4
  # devices: [0, 1]
  devices: [2]
  # devices: [1]
  accelerator: "auto"
  max_epochs: 1000
  precision: "bf16-mixed"
  check_val_every_n_epoch: 10
  # strategy: "ddp_find_unused_parameters_true"
  # fast_dev_run: true

